{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2., nan],\n",
      "        [ 4., nan,  6.],\n",
      "        [nan,  8.,  9.],\n",
      "        [10., 11., 12.],\n",
      "        [nan, nan, nan]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a PyTorch tensor with missing data (NaN) for testing\n",
    "missing_data_tensor = torch.tensor([\n",
    "    [1.0, 2.0, float('nan')],\n",
    "    [4.0, float('nan'), 6.0],\n",
    "    [float('nan'), 8.0, 9.0],\n",
    "    [10.0, 11.0, 12.0],\n",
    "    [float('nan'), float('nan'), float('nan')]\n",
    "])\n",
    "\n",
    "print(missing_data_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ignoring or Dropping Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Data\n",
    "\n",
    "Dealing with missing data is a critical step in data preprocessing and analysis. Here are various methods to address missing data, categorized into three main approaches:\n",
    "\n",
    "| **Category**                 | **Method**                                                                                  | **Description**                                                                                                                                   | **Pros**                                | **Cons**                                              |\n",
    "|------------------------------|---------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------|-------------------------------------------------------|\n",
    "| **1. Ignoring or Dropping**  | **Listwise Deletion**                                                                       | Remove rows where any value is missing.                                                                                                           | Simple to implement.                    | Loss of data.                                         |\n",
    "|                              | **Column-Wise Deletion**                                                                    | Drop columns with a high proportion of missing values.                                                                                           | Useful for irrelevant columns.          | Loss of features.                                     |\n",
    "| **2. Statistical Imputation**| **Mean/Median/Mode Imputation**                                                             | Replace missing values with the mean, median, or mode of the column.                                                                             | Quick and easy.                          | Reduces variability in data.                         |\n",
    "|                              | **Forward/Backward Fill**                                                                   | Fill missing values using the previous or next observations.                                                                                     | Useful in time series data.             | Assumes data continuity.                             |\n",
    "|                              | **Random Imputation**                                                                       | Replace missing values with random values from the column.                                                                                       | Preserves data distribution.             | Adds randomness.                                     |\n",
    "| **2. Predictive Imputation** | **Regression Imputation**                                                                   | Use regression models to predict missing values based on other variables.                                                                        | More accurate.                           | Computationally expensive.                           |\n",
    "|                              | **k-Nearest Neighbors (KNN)**                                                               | Replace missing values with the average or mode of the k-nearest neighbors.                                                                      | Captures variable relationships.         | Computationally intensive for large datasets.        |\n",
    "|                              | **Multivariate Imputation by Chained Equations (MICE)**                                     | Impute data by iteratively modeling each variable based on the others.                                                                           | Effective for complex datasets.          | Computationally expensive.                           |\n",
    "| **2. Advanced Techniques**   | **Deep Learning or ML Models**                                                             | Use models like random forests or neural networks to predict missing values.                                                                     | Captures complex patterns.               | Requires significant resources.                      |\n",
    "|                              | **Multiple Imputation**                                                                     | Generate multiple datasets, analyze, and combine results.                                                                                        | Captures uncertainty in imputations.     | More complex process.                                |\n",
    "|                              | **Domain-Specific Imputation**                                                              | Use heuristics or domain rules to fill missing values.                                                                                           | Leverages domain knowledge.              | Requires domain expertise.                           |\n",
    "| **3. Transformation**        | **Create Missing Indicator**                                                               | Add a binary variable indicating missing data.                                                                                                   | Preserves missingness information.       | Adds dimensionality.                                 |\n",
    "|                              | **Replace with Constant**                                                                   | Replace missing values with a constant (e.g., `0`, `-1`).                                                                                        | Simple to implement.                     | May distort interpretation.                          |\n",
    "|                              | **Binning**                                                                                 | Transform continuous variables into categorical bins.                                                                                            | Useful for specific cases.               | Loss of granularity.                                 |\n",
    "| **4. Data Integration**      | **External Data Sources**                                                                   | Use additional data to infer missing values.                                                                                                     | Can improve accuracy.                    | Limited by availability of external data.            |\n",
    "|                              | **Data Augmentation**                                                                       | Generate synthetic data points to supplement missing data.                                                                                       | Can enhance datasets.                    | May introduce noise or bias.                         |\n",
    "| **5. Model-Specific Handling**| **Model Tolerance**                                                                         | Use algorithms that handle missing data natively (e.g., XGBoost, LightGBM).                                                                      | No preprocessing required.               | Limited to specific algorithms.                      |\n",
    "|                              | **Use Data Directly**                                                                       | Use models capable of handling missing values without transformation.                                                                            | Simplifies workflow.                     | May not work for all models.                         |\n",
    "| **6. Analysis Adaptation**   | **Sensitivity Analysis**                                                                    | Test how imputation methods affect results.                                                                                                      | Ensures robust results.                  | Requires additional analysis.                        |\n",
    "|                              | **Weighting or Reweighting**                                                                | Adjust weights for missing observations based on known distributions.                                                                            | Maintains overall accuracy.              | Requires distributional assumptions.                 |\n",
    "| **7. Do Nothing**            | **Leave Missing Values Unchanged**                                                         | Suitable for models that work with missing data directly (e.g., some deep learning models).                                                      | Simplifies process.                      | May reduce accuracy for some methods.                |\n",
    "\n",
    "---\n",
    "\n",
    "### **Choosing the Right Method**\n",
    "\n",
    "The choice depends on:\n",
    "- **Data Size:** Large datasets tolerate listwise deletion better than small ones.\n",
    "- **Data Type:** Numerical or categorical data.\n",
    "- **Missingness Pattern:** MCAR, MAR, or MNAR.\n",
    "- **Domain Knowledge:** Contextual understanding of the problem.\n",
    "- **Analysis Goal:** Predictive accuracy, interpretability, or exploratory insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
